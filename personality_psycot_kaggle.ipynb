{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAyamUwUIAVj",
        "outputId": "000825ff-63f5-4e1e-a307-0ab6e9415f45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langchain==0.0.147\n",
            "  Downloading langchain-0.0.147-py3-none-any.whl (626 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.5/626.5 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.147) (6.0)\n",
            "Collecting SQLAlchemy<2,>=1 (from langchain==0.0.147)\n",
            "  Downloading SQLAlchemy-1.4.48-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp<4.0.0,>=3.8.3 (from langchain==0.0.147)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0.0,>=4.0.0 (from langchain==0.0.147)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain==0.0.147)\n",
            "  Downloading dataclasses_json-0.5.8-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.147) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.147) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain==0.0.147)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.147) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.147) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.147) (8.2.2)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.147) (4.65.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.147) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.147) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.147)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.147)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.147)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.147)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.147)\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.147)\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.147)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain==0.0.147) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.147) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.147) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.147) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2,>=1->langchain==0.0.147) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.147) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.147)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: SQLAlchemy, mypy-extensions, multidict, marshmallow, frozenlist, async-timeout, yarl, typing-inspect, openapi-schema-pydantic, marshmallow-enum, aiosignal, dataclasses-json, aiohttp, langchain\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.10\n",
            "    Uninstalling SQLAlchemy-2.0.10:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.10\n",
            "Successfully installed SQLAlchemy-1.4.48 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 dataclasses-json-0.5.8 frozenlist-1.3.3 langchain-0.0.147 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.9.0 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tiktoken==0.3.2\n",
            "  Downloading tiktoken-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.2) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.2) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.2) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.2) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.2) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.2) (3.4)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.3.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.0.147\n",
        "!pip install tiktoken==0.3.2\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVIX1dSlIxS5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from langchain.schema import Document\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "import tiktoken\n",
        "from langchain import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "import sys\n",
        "sys.path.append('drive/MyDrive/Colab Notebooks')\n",
        "\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"]= \"YOUR API KEY\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtUiUaEpYGzj"
      },
      "source": [
        "## Load File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKmEGADmXPqn"
      },
      "outputs": [],
      "source": [
        "task = '3'\n",
        "rev_label = False\n",
        "shuffle = False\n",
        "file_name = \"mbti_test_zero_psycot_{}.csv\".format(task)\n",
        "\n",
        "with open('Kaggle/test.pkl', 'rb') as f:\n",
        "  data = pickle.load(f)\n",
        "def process_data(data):\n",
        "  poster = data['posts_text']\n",
        "  label = data['annotations']\n",
        "  label_lookup = {'E': 1, 'I': 0, 'S': 1, 'N':0, 'T': 1, 'F': 0, 'J': 1, 'P':0}\n",
        "  persona_lookup = {}\n",
        "  poster_data = [{'posts': t, 'label0': label_lookup[list(label[i])[0]],\n",
        "          'label1': label_lookup[list(label[i])[1]],'label2': label_lookup[list(label[i])[2]],\n",
        "          'label3': label_lookup[list(label[i])[3]]} for i,t in enumerate(poster)]\n",
        "  return poster_data\n",
        "poster_data = process_data(data)\n",
        "texts = [item['posts'] for item in poster_data]\n",
        "labels = [item['label{}'.format(task)] for item in poster_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "x7OJZ7DtFjOG",
        "outputId": "d01c9db1-17dc-4f3b-d62c-0b6d66eefe74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'INFJ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "data['annotations'][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvpbBX-cYRVJ"
      },
      "source": [
        "## Define Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XHmcQa2YVLh"
      },
      "outputs": [],
      "source": [
        "if task == '0':\n",
        "  qa_id = [3, 6, 9, 13, 16, 21, 24, 26, 29, 36, 43] # A: \"\" or B: \"\".\n",
        "  qa_list = ['The author is usually: A: \"A good mixer with gropus of people\", B: \"Quiet and reserved\", or C: \"Not sure whether A or B\"',\n",
        "        'Among the author\\'s friends, the author is: A: \"Full of news about everybody\", B: \"One of the last to hear what is going on\", or C: \"Not sure whether A or B\"',\n",
        "        'The author tends to have: A: \"A broad range of friendships with many different people\", B: \"Deep friendship with very few people\", or C: \"Not sure whether A or B\"',\n",
        "        'When the author is with a group of people, the author is usually: A: \"Join in the talk of the group\", B: \"Stand back and listen first\", or C: \"Not sure whether A or B\"',\n",
        "        'The author is: A: \"Talk easily to almost anyone\", B: \"Find a lot to say only to certain people or under certain conditions\", or C: \"Not sure whether A or B\"',\n",
        "        'In a large group, the author is more often: A: \"Introduce others\", B: \"Get introduced\", or C: \"Not sure whether A or B\"',\n",
        "        'When the author meets the new people, the author tells what they are interested in: A: \"Right away\", B: \"Only after people to get to know the author\", or C: \"Not sure whether A or B\"',\n",
        "        'The author is usually: A: \"Show their feelings freely\", B: \"Keep their feelings to themselves\", or C: \"Not sure whether A or B\"',\n",
        "        'Which word is more suitable for the author: A: \"QUIET\", B: \"HEARTY\", or C: \"Not sure whether A or B\"',\n",
        "        'Which word is more suitable for the author: A: \"RESERVED\", B: \"TALAKATIVE\", or C: \"Not sure whether A or B\"',\n",
        "        'Which word is more suitable for the author: A: \"CALM\", B: \"LIVELY\", or C: \"Not sure whether A or B\"',\n",
        "        ]\n",
        "  if not rev_label:\n",
        "    trait_choice = 'A: \"Extraversion\" or B: \"Introversion\"'\n",
        "  else:\n",
        "    trait_choice = 'A: \"Introversion\" or B: \"Extraversion\"'\n",
        "elif task == '1':\n",
        "  qa_id = [2, 5, 10, 12, 15, 20, 23, 28, 31, 35, 38, 42, 45, 48]\n",
        "  qa_list = ['If the author was a teacher, would they rather teach: A: \"Facts-based courses\", B: \"Courses involving opinion or theory\", or C: \"Not sure whether A or B\"',\n",
        "        'In doing something that many other people do would the author rather: A: \"Invent a way of their own\", B: \"Do it in the accepted way\", or C: \"Not sure whether A or B\"',\n",
        "        'Does the author admire more the people who are: A: \"Normal-acting to never make themselves the center of attention\", B: \"Too original and individual to care whether they are the center of attention or not\", or C: \"Not sure whether A or B\"',\n",
        "        'Does the author usually get along better with: A: \"Realistic people\", B: \"Imaginative people\", or C: \"Not sure whether A or B\"',\n",
        "        'In reading for pleasure, does the author: A: \"Enjoy odd or original ways of saying things\", B: \"Like writers to say exactly what they mean\", or C: \"Not sure whether A or B\"',\n",
        "        'Would the author rather be considered: A: \"A practical person\", B: \"An out-of-the-box-thinking person\", or C: \"Not sure whether A or B\"',\n",
        "        'Would the author rather has a friend: A: \"Someone who is always coming up with new ideas\", B: \"Someone who has both feet on the ground\", or C: \"Not sure whether A or B\"',\n",
        "        'Which word is more suitable for the author: A: \"FACTS\", B: \"IDEAS\", or C: \"Not sure whether A or B\"',\n",
        "        'Which word is more suitable for the author: A: \"IMAGINATIVE\", B: \"MATTER-OF-FACT\", or C: \"Not sure whether A or B\"',\n",
        "        'Which word is more suitable for the author: A: \"STATEMENT\", B: \"CONCEPT\", or C: \"Not sure whether A or B\"',\n",
        "        'Which word is more suitable for the author: A: \"CREATE\", B: \"MAKE\", or C: \"Not sure whether A or B\"',\n",
        "        'Which word is more suitable for the author: A: \"CERTAINTY\", B: \"THEORY\", or C: \"Not sure whether A or B\"',\n",
        "        'Which word is more suitable for the author: A: \"FASCINATING\", B: \"SENSIBLE\", or C: \"Not sure whether A or B\"',\n",
        "        'Which word is more suitable for the author: A: \"LITERAL\", B: \"FIGURATIVE\", or C: \"Not sure whether A or B\"',\n",
        "        ]\n",
        "  if not rev_label:\n",
        "    trait_choice = 'A: \"Sensing\" or B: \"Intuition\"'\n",
        "  else:\n",
        "    trait_choice = 'A: \"Intuition\" or B: \"Sensing\"'\n",
        "elif task == '2':\n",
        "  qa_id = [4, 14, 22, 30, 32, 33, 37, 39, 40, 44, 46, 47, 49, 50]\n",
        "  qa_list = ['Does the author more often let: A: \"Their heart rule their head\", B: \"Their head rule their heart\", or C: \"Not sure whether A or B\"',\n",
        "        'For the author, which is a higher compliment: A: \"A person of real feeling\", B: \"A consistently reasonable person\", or C: \"Not sure whether A or B\"',\n",
        "        'Does the author usually: A: \"Value emotion more than logic\", B: \"Value logic more than feelings\", or C: \"Not sure whether A or B\"',\n",
        "        'Which word is more suitable for the author: A: \"CONVINCING\", B: \"TOUCHING\", or C: \"Not sure whether A or B\"',\n",
        "        'Which word is more suitable for the author: A: \"BENEFITS\", B: \"BLESSINGS\", or C: \"Not sure whether A or B\"',\n",
        "        'Which word is more suitable for the author: A: \"PEACEMAKER\", B: \"JUDGE\", or C: \"Not sure whether A or B\"',\n",
        "        'Which word is more suitable for the author: A: \"ANALYZE\", B: \"SYMPATHIZE\", or C: \"Not sure whether A or B\"',\n",
        "        'Which word is more suitable for the author: A: \"DETERMINED\", B: \"DEVOTED\", or C: \"Not sure whether A or B\"',\n",
        "        'Which word is more suitable for the author: A: \"GENTLE\", B: \"FIRM\", or C: \"Not sure whether A or B\"',\n",
        "        'Which word is more suitable for the author: A: \"JUSTICE\", B: \"MERCY\", or C: \"Not sure whether A or B\"',\n",
        "        'Which word is more suitable for the author: A: \"FIRM-MINDED\", B: \"WARM HEARTED\", or C: \"Not sure whether A or B\"',\n",
        "        'Which word is more suitable for the author: A: \"FEELING\", B: \"THINKING\", or C: \"Not sure whether A or B\"',\n",
        "        'Which word is more suitable for the author: A: \"ANTICIPATION\", B: \"COMPASSION\", or C: \"Not sure whether A or B\"',\n",
        "        'Which word is more suitable for the author: A: \"HARD\", B: \"SOFT\", or C: \"Not sure whether A or B\"',\n",
        "        ]\n",
        "  if not rev_label:\n",
        "    trait_choice = 'A: \"Thinking\" or B: \"Feeling\"'\n",
        "  else:\n",
        "    trait_choice = 'A: \"Feeling\" or B: \"Thinking\"'\n",
        "elif task == '3':\n",
        "  qa_id = [18, 1, 7, 8, 11, 17, 19, 25, 27, 34, 41]\n",
        "  # qa_id = [27]\n",
        "  qa_list = [\n",
        "      'When it is settled well in advance that the author will do a certain thing at a certain time, does the author find it: A: \"Nice to be able to plan accordingly\", B: \"A little unpleasant to be tied down\", or C: \"Not sure whether A or B\"',\n",
        "        'When the author goes somewhere, would the author rather: A: \"Plan what they will do and When\", B: \"Just go\", or C: \"Not sure whether A or B\"',\n",
        "        'Does the idea of making a list of what the author should get done over a weekend: A: \"Help the author\", B: \"Stress the author\", C: \"Positively depress the author\", or D: \"Not sure whether A, B, or C\"',\n",
        "        'When the author have a special job to do, does the author like to: A: \"Organize it carefully before they start\", B: \"Find out what is necessary as they go along\", or C: \"Not sure whether A or B\"',\n",
        "        'Does the author prefer to: A: \"Arrange picnics, parties etc, well in advance\", B: \"Be free to do whatever to looks like fun when the time comes\", or C: \"Not sure whether A or B\"',\n",
        "        'Does following a schedule: A: \"Appeal to the author\", B: \"Cramp the author\", or C: \"Not sure whether A or B\"',\n",
        "        'Is the author more successful: A: \"At following a carefully worked out plan\", B: \"At dealing with the unexpected and seeing quickly what should be done\", or C: \"Not sure whether A or B\"',\n",
        "        'In author\\'s daily work, does the author: A: \"Usually plan their work so the author won\\’t need to work under pressure\", B: \"Rather enjoy an emergency that makes their work against time\", or C: \"Hate to work under pressure\", or D: \"Not sure whether A, B, or C\"',\n",
        "        'Which word is more suitable for the author: A: \"SCHEDULED\", B: \"UNPLANNED\", or C: \"Not sure whether A or B\"',\n",
        "        'Which word is more suitable for the author: A: \"SYSTEMATIC\", B: \"SPONTANEOUS\", or C: \"Not sure whether A or B\"',\n",
        "        'Which word is more suitable for the author: A: \"SYSTEMATIC\", B: \"CASUAL\", or C: \"Not sure whether A or B\"',\n",
        "        ]\n",
        "  if not rev_label:\n",
        "    trait_choice = 'A: \"Judging\" or B: \"Perceiving\"'\n",
        "  else:\n",
        "    trait_choice = 'A: \"Perceiving\" or B: \"Judging\"'\n",
        "\n",
        "def cteat_agent(trait_choice, text):\n",
        "  perfix_temp = 'You are an AI assistant who specializes in text analysis and I am Human. We will complete a text analysis task together through a multi-turn dialogue. '\\\n",
        "          'The task is as follows: we have a set of posts written by an author, and at each turn I will give you a Question about the author. According to the author\\'s posts, '\\\n",
        "          'you need to choose the possible options. '\\\n",
        "          'After opting all the choices, I will ask you if the author is {}, and then you need to give your choice. \\nAUTHOR\\'S POSTS: {}\\n'.format(trait_choice, text)\n",
        "  Prompt_temp = perfix_temp + \\\n",
        "          '{history}\\n'\\\n",
        "          'Human: {human}\\n'\\\n",
        "          'Assistant: '\n",
        "  prompt = PromptTemplate(\n",
        "      input_variables=[\"history\", \"human\"],\n",
        "      template=Prompt_temp)\n",
        "  memory = ConversationBufferMemory(human_prefix='Human', ai_prefix='Assistant', memory_key=\"history\")\n",
        "  llm = OpenAI(temperature=0.0, model_name='gpt-3.5-turbo-0301')\n",
        "  agent = LLMChain(llm=llm, prompt=prompt, verbose=False, memory=memory,)\n",
        "  return agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SU_tg3XJ64a7",
        "outputId": "916c7e05-b49f-4214-80ea-5466228d2205"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['When it is settled well in advance that the author will do a certain thing at a certain time, does the author find it: A: \"Nice to be able to plan accordingly\", B: \"A little unpleasant to be tied down\", or C: \"Not sure whether A or B\"',\n",
              " 'When the author goes somewhere, would the author rather: A: \"Plan what they will do and When\", B: \"Just go\", or C: \"Not sure whether A or B\"',\n",
              " 'Does the idea of making a list of what the author should get done over a weekend: A: \"Help the author\", B: \"Stress the author\", C: \"Positively depress the author\", or D: \"Not sure whether A, B, or C\"',\n",
              " 'When the author have a special job to do, does the author like to: A: \"Organize it carefully before they start\", B: \"Find out what is necessary as they go along\", or C: \"Not sure whether A or B\"',\n",
              " 'Does the author prefer to: A: \"Arrange picnics, parties etc, well in advance\", B: \"Be free to do whatever to looks like fun when the time comes\", or C: \"Not sure whether A or B\"',\n",
              " 'Does following a schedule: A: \"Appeal to the author\", B: \"Cramp the author\", or C: \"Not sure whether A or B\"',\n",
              " 'Is the author more successful: A: \"At following a carefully worked out plan\", B: \"At dealing with the unexpected and seeing quickly what should be done\", or C: \"Not sure whether A or B\"',\n",
              " 'In author\\'s daily work, does the author: A: \"Usually plan their work so the author won\\\\’t need to work under pressure\", B: \"Rather enjoy an emergency that makes their work against time\", or C: \"Hate to work under pressure\", or D: \"Not sure whether A, B, or C\"',\n",
              " 'Which word is more suitable for the author: A: \"SCHEDULED\", B: \"UNPLANNED\", or C: \"Not sure whether A or B\"',\n",
              " 'Which word is more suitable for the author: A: \"SYSTEMATIC\", B: \"SPONTANEOUS\", or C: \"Not sure whether A or B\"',\n",
              " 'Which word is more suitable for the author: A: \"SYSTEMATIC\", B: \"CASUAL\", or C: \"Not sure whether A or B\"']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "qa_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UG6y6kGQ2WaJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "def shuffle_post(posts_list):\n",
        "  shuffle_index = shuffle([i for i in range(len(posts_list))], random_state=0)\n",
        "  shuffle_post_list = [posts_list[j] for j in shuffle_index]\n",
        "  return shuffle_post_list\n",
        "\n",
        "if not os.path.exists(file_name):\n",
        "  rest_sample = 0\n",
        "  head = {\"text\": [], 'gold': [], 'assessment': [], 'answers': []}\n",
        "  data = pd.DataFrame(head)\n",
        "  data.to_csv(file_name, mode='w', index=False, header=True)\n",
        "else:\n",
        "  data = pd.read_csv(file_name)\n",
        "  rest_sample = len(list(data['gold']))\n",
        "print('Done: {}/{}'.format(rest_sample, len(texts)))\n",
        "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
        "for i in range(rest_sample, len(texts)):\n",
        "  print('Done: {}/{}'.format(i, len(texts)))\n",
        "  posts = ''\n",
        "  count = 1\n",
        "  if shuffle:\n",
        "    posts_list = shuffle_post(texts[i])\n",
        "  else:\n",
        "    posts_list = texts[i]\n",
        "  for j in range(len(posts_list)):\n",
        "    if len(posts_list[j])>10:\n",
        "      post = tokenizer.decode(tokenizer.encode(posts_list[j].replace('{', '').replace('}', ''))[:80])\n",
        "      posts += 'Post{}: {}; '.format(count,post)\n",
        "      count += 1\n",
        "  print(posts)\n",
        "  agent = cteat_agent(trait_choice, posts)\n",
        "  assessment = {}\n",
        "  for k, ques in enumerate(qa_list):\n",
        "    if k == 0:\n",
        "      statments = \"Q: {}. Provide a choice ID in the format: \\\"CHOICE: <A/B/C>\\\", and do not give the explanation.\".format(ques)\n",
        "    elif qa_id[k]==7 or qa_id[k]==25:\n",
        "      statments = \"Q: {}. Provide a choice in the format: \\\"CHOICE: <A/B/C/D>\\\".\".format(ques)\n",
        "    else:\n",
        "      statments = \"Q: \\\"{}\\\".\".format(ques)\n",
        "    response = agent.predict(human=statments)\n",
        "    assessment['S{}'.format(qa_id[k])] = response\n",
        "    # print(response)\n",
        "  trait_ques = 'According to above, the author is more likely to be: {}. Provide a choice in the format: \"CHOICE: <A/B>\" and do not give the explanation.'.format(trait_choice)\n",
        "  answer = agent.predict(human=trait_ques)\n",
        "  print(answer, labels[i])\n",
        "  print(assessment)\n",
        "  api_data = pd.DataFrame([[posts, labels[i], assessment, answer]])\n",
        "  api_data.to_csv(file_name, mode='a', index=False, header=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}